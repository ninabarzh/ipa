---
title: "Deepfake defence workshop"
linkTitle: "Deepfake defence"
weight: 3
_build:
  render: always
description: "A survivor-first, anti-jargon workshop to spot, question, and defend against deepfake abuse. No tech background needed—just eyes, instincts, and a bit of theatre."
menu:
  sidebar:
    weight: 15
    identifier: "en-deepfake-defence"
    parent: "en-docs"
translationKey: "deepfake-defence"
---

**Audience**: Survivors, support workers, social workers, advocates, and allies

**Duration**: 90 minutes (adaptable)

Deepfakes are not just a tech curiosity. In the wrong hands, they are used to harass, discredit, or isolate people — 
especially survivors of abuse. This session arms participants with the confidence to spot digital manipulation, 
respond calmly, and help others do the same.

## What participants will walk away with

* A clear understanding of what deepfakes are and how they are misused in abuse and coercive control
* Practical tools to detect fake video, audio, and images
* Real-world strategies for responding safely when synthetic media is used as a weapon
* A printed checklist of red flags and steps to take — something to keep, share, or pass along

## What you will need

* Projector or large screen
* Laptops/tablets (optional for hands-on use)
* Flipchart or whiteboard
* Printed checklists
* Pre-selected real and fake video/audio clips
* Roleplay scenario cards

## Session plan

### Plain talk: what is a deepfake? (15 minutes)

**Facilitator brief**: Explain clearly. No need for tech lectures.

* A deepfake is a digitally altered video, audio or photo that looks or sounds like someone doing or saying something they never actually did.
* Abusers may use them to fabricate revenge porn, false confessions, threats, or humiliating footage.
* Not all deepfakes are malicious, but in abusive contexts they can escalate fear, confusion, and loss of trust.

Analogy (optional): *“It’s like a puppet that looks like you, talks like you, and fools people into believing it *is* you — except it’s made by someone with bad intentions and spread online.”*

### How to spot a fake (15 minutes)

**Group brainstorm**: “If you had to fake someone in a video, what might go wrong?”
Note ideas, then offer a [printed checklist (example)](deepfake-response-kit/#checklist-card--how-to-spot-a-deepfake-or-digital-hoax):

**Common deepfake warning signs**:

* Lip movements don’t match the words
* No blinking — or too much blinking
* Lighting or shadows look ‘off’
* Eyes look frozen or flat
* Ears, jewellery, or hair blur or melt
* Voice sounds robotic or lacks emotion
* Same expressions repeated unnaturally

Print small cards with this checklist for participants to keep.

### Spot-the-fake exercise (20 minutes)

[Show 5 clips](creating-fakes.md) — a mix of real and faked content. After each one:

* Ask participants: *Real or fake?*
* Vote, reveal, and discuss:

  * “What gave it away?”
  * “Would it fool someone who didn’t know better?”
  * “What damage could this do?”

Include one obvious and one subtle example to show the spectrum.

### Scenario roleplay: If it was used against you (20 minutes)

Break into small groups. Each group gets one [scenario card (A6 format)](deepfake-response-kit/#scenario-cards). These describe realistic deepfake or 
impersonation threats survivors or volunteers might face.

The scenario might involve:

* A fake nude video spreading in private groups
* A voice message impersonating your boss asking for passwords
* A video where “you” appear to admit to something you never said
* A viral video that looks real, but smells off

Each group discusses three questions. Then, each group shares one insight or tip with everyone.

*Facilitator cue:* Normalise doubt. These tools are meant to deceive. There is strength in pausing and checking — not reacting fast.

### If someone uses a deepfake to target you (10 minutes)

**Practical actions**:

* Take a breath — you are not alone, and this can be handled
* Save the evidence (video, screenshot, link)
* Write down when and where you saw it
* Report it on the platform (abuse of synthetic media is banned on most)
* Get support — legal, emotional, digital
* Do **not** confront the person behind it alone

Encourage contacting a support worker before taking steps.

### Questions & myth-busting (10 minutes)

Open floor for Q\&A. [Address common myths](facilitator-guide/#myth-busting-cues):

* *“You have to be famous to be targeted”* – Not true.
* *“Deepfakes are perfect now”* – Still flawed.
* *“If it looks real, it *is* real”* – Exactly the trap.

## Optional extras

* **Mini demo**: If safe, show a voice or face clone using free tools, then debrief how this tech is being abused.
* **Takeaway pack**: Printable PDF or card with:

  * Red flag checklist
  * What to do if targeted
  * Local support services
  * Reporting guidance

- **Follow-up**: Book a 1:1 drop-in session to get help with reporting or verifying media content.
